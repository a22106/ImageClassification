{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist CNN\n",
    "- layer 1 </br>\n",
    "Conv: in_c = 1, out_c = 32, kernel = 3, stride = 1, padding = 1 </br>\n",
    "ReLU: </br>\n",
    "MaxPool: kernel = 2, stride = 2 </br>\n",
    "\n",
    "- layer 2 </br>\n",
    "Conv: in_c = 32, out_c = 64, kernel = 3, stride = 1, padding = 1 </br>\n",
    "ReLU: </br>\n",
    "MaxPool: kernel = 2, stride = 2 </br>\n",
    "</br>\n",
    "- view </br>\n",
    "FC\n",
    "\n",
    "- Cross Entropy Loss </br>\n",
    "SoftMax </br>\n",
    "NLL Loss\n",
    "\n",
    "\n",
    "- view => (batchsize x [7, 7, 64]) => batch_size x [3136]) </br>\n",
    "Fully_Connect layer => (input = 3136, output = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import torch.nn.init\n",
    "\n",
    "inputs = torch.Tensor(1, 1, 28, 28) # (batch, channel, height, width)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "training_epochs = 15\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist digit data\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', \n",
    "                          train = True,\n",
    "                          transform= transforms.ToTensor(),\n",
    "                          download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=False,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion mnist data\n",
    "fashion_train = dsets.FashionMNIST.train_data(root=\"data/FashionMNIST/train\",\n",
    "                                         train=True,\n",
    "                                         transform=transforms.ToTensor(),\n",
    "                                         download=True)\n",
    "fashion_test = dsets.FashionMNIST.test_data(root=\"data/FashionMNIST/test\",\n",
    "                                         train=False,\n",
    "                                         transform=transforms.ToTensor(),\n",
    "                                         download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train_loader = DataLoader(fashion_train,\n",
    "                                  batch_size=10,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last= True)\n",
    "fashion_test_loader = DataLoader(fashion_test,\n",
    "                                 batch_size=10,\n",
    "                                 shuffle=True,\n",
    "                                 drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n",
      "tensor([7, 6, 7, 2, 4, 6, 5, 7, 2, 1])\n",
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fashion_train_imgs, fashion_train_labels = next(iter(fashion_train_loader))\n",
    "num_classes = len(dsets.FashionMNIST.classes)\n",
    "print(fashion_train_imgs.shape)\n",
    "print(fashion_train_labels)\n",
    "print(dsets.FashionMNIST.classes)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow( fashion_train_imgs[i].permute(1, 2, 0), cmap='gray')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 101 model\n",
    "model = resnet.resnet101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "metrics = {\n",
    "    'accuracy': Accuracy(),\n",
    "    'nll': Loss(criterion),\n",
    "    'confusion matrix': ConfusionMatrix(num_classes=10),\n",
    "}\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "training_history = {'accuracy': [], 'loss':[]}\n",
    "validation_history = {'accuracy': [], 'loss': []}\n",
    "last_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3,stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3,stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(7*7*64, 10, bias=True) # Fully connected Layer\n",
    "        nn.init.xavier_uniform_(self.fc.weight) # FC 레이어 초기화\n",
    "\n",
    "    def forward(self, x): # x가 out됨\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "\n",
    "        out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # chnl-in, out, kernel\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) \n",
    "        self.fc1 = nn.Linear(1024, 512) # [64*4*4, x]\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)   # 10 classes\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.drop2 = nn.Dropout(0.50)\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            self.conv1,     # x in [bs, 1, 28, 28]\n",
    "            nn.ReLU(),      # size([bs, 32, 24, 24])\n",
    "            self.pool,  # size([bs, 32, 12, 12])\n",
    "            self.drop1\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            self.conv2,             # size([bs, 64, 8, 8])\n",
    "            nn.ReLU(),    \n",
    "            self.pool   # size([bs, 64, 4, 4])\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            self.fc1,   # size(bs, 512)\n",
    "            nn.ReLU(),\n",
    "            self.drop2,\n",
    "            self.fc2,   # size(bs, 256)\n",
    "            nn.ReLU(),\n",
    "            self.fc3   # size(bs, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv phase                    \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "\n",
    "\n",
    "        # neural network phase\n",
    "        out = out.reshape(-1, 1024)    # size([bs, 1024]) \n",
    "        out = self.layer3(out)     \n",
    "        return out\n",
    "\n",
    "def accuracy(model, ds):\n",
    "    ldr = T.utils.data.DataLoader(ds, batch_size=len(ds), shuffle=False)\n",
    "    n_correct = 0\n",
    "    for data in ldr:\n",
    "        (pixels, labels) = data\n",
    "    with T.no_grad():\n",
    "        oupts = model(pixels)\n",
    "        _, predicteds = torch.max(oupts, 1)\n",
    "        n_correct += (predicteds == labels).sum().item()\n",
    "\n",
    "    acc = (n_correct * 1.0) / len(ds)\n",
    "    return acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout(p=0.25, inplace=False)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANpUlEQVR4nO3de4xc9XnG8eexWdtgQPFCcS3jBkhcgtuCHW1MICaiQUm4tDKRImT/gdzK0qYtSBBRJRaREvJHFYeWoEqlSU3i4lZchEoiiGopdpykDnHqsIDjC4SYIhPb8gXbalkS8Pry9o89oAV2frueO/t+P9JoZs57zp5XYz975pzfzP4cEQIw8U3qdAMA2oOwA0kQdiAJwg4kQdiBJE5r586meGpM0/R27hJI5Q39VkNx1KPVGgq77Wsl/aOkyZK+HRErS+tP03Rd7msa2SWAgs2xoWat7rfxtidLuk/SdZLmSVpqe169Pw9AazVyzr5Q0osR8VJEDEl6RNLi5rQFoNkaCftsSbtHPN9TLXsb2/22B2wPHNPRBnYHoBEtvxofEasioi8i+no0tdW7A1BDI2HfK2nOiOfnV8sAdKFGwv6UpLm2L7Q9RdISSU80py0AzVb30FtEHLd9q6QfaHjobXVE7GhaZwCaqqFx9ohYK2ltk3oB0EJ8XBZIgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJNo6ZTNa49f/8pGatU3X3VvcdtFjf1usX/D9Y8X6aT96ulhH9+DIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+EYRrlqa5/Pv87hseKtY/8dn9xfpDgxcX6/esv6Fm7UPfOlzc9sTzO4t1nJqGwm57l6RBSSckHY+IvmY0BaD5mnFk/9OIONSEnwOghThnB5JoNOwhaZ3tp233j7aC7X7bA7YHjulog7sDUK9G38Yvioi9ts+TtN72ryJi48gVImKVpFWSdLZ7o8H9AahTQ0f2iNhb3R+U9D1JC5vRFIDmqzvstqfbPuvNx5I+JWl7sxoD0FyOqO+dte2LNHw0l4ZPBx6KiL8rbXO2e+NyX1PX/lDb/958Rc3a0ffVHoOXpHN2lK+jXPL18u/vu2f9tFjv8eSatR1Dx4vb3rH8b4p1vkv/bptjg16NI6P+o9d9zh4RL0m6rO6uALQVQ29AEoQdSIKwA0kQdiAJwg4kUffQWz0Yept4jvxl7WE/SfJna39H6mfzHyluu3XoRLH+5Sv+vFg/vv9AsT4RlYbeOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6Nj9n7xymJ9+23/XKw/OHhOuX5l7S9lnjh8pLjtexXj7AAIO5AFYQeSIOxAEoQdSIKwA0kQdiAJpmxGx8z++qZi/c4llxbrXz3v2WL9gUv+oGZt0pMTc5y9hCM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBODu61pIZvxhjjZ629DFRjHlkt73a9kHb20cs67W93vbO6n5Ga9sE0KjxvI1/QNK171i2QtKGiJgraUP1HEAXGzPsEbFR0js/W7hY0prq8RpJNza3LQDNVu85+8yI2Fc93i9pZq0VbfdL6pekaTqjzt0BaFTDV+Nj+C9W1vyrlRGxKiL6IqKvR1Mb3R2AOtUb9gO2Z0lSdX+weS0BaIV6w/6EpGXV42WSHm9OOwBaZcxzdtsPS7pa0rm290j6iqSVkh61vVzSy5JuamWTmJgmXfqhYv2Pep4p1rcNHSvWe155rWatPPP7xDRm2CNiaY0Ssz0A7yF8XBZIgrADSRB2IAnCDiRB2IEk+IorGjL5nN5i/dCfXVyz9rUvr2po35//61uL9SkvPNXQz59oOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6No6NN9xfpFX/1Vsf74nH+qWXt4sOZfM5Mk9X2j/M3p89ZtLtbxdhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlRtGfZ8WJ93Zz/Ktb7d19ds3bghvKUy+cd3lSs49RwZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnR9GF95Xrhxa9Xqz/ZMslNWt/ePgX9bSEOo15ZLe92vZB29tHLLvL9l7bW6rb9a1tE0CjxvM2/gFJ146y/N6ImF/d1ja3LQDNNmbYI2KjpCNt6AVACzVyge5W21urt/kzaq1ku9/2gO2BYzrawO4ANKLesH9T0gckzZe0T9I9tVaMiFUR0RcRfT2aWufuADSqrrBHxIGIOBERJyXdL2lhc9sC0Gx1hd32rBFPPyNpe611AXSHMcfZbT8s6WpJ59reI+krkq62PV9SSNol6XOtaxGd5J9tKdZ3Hj+zWP/XT367Zu1rurSellCnMcMeEUtHWfydFvQCoIX4uCyQBGEHkiDsQBKEHUiCsANJ8BVXNORkcLx4r+BfCkiCsANJEHYgCcIOJEHYgSQIO5AEYQeSmDDj7HHFZcW6f/7LNnUysRy97iPF+oKpPy/Wnz06vZntoAEc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiQkzzj7UO6VY/819lxfrc2/Z3Mx2JoyhsycX62e4/Lo/eqQ0f8gbdXSEenFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkJsw4++m7B4v1FZ/YWKyv++m8Yn3wqkOn3NNE8MoCF+uTVK7/aO2Ha9ber0119YT6jHlktz3H9o9tP2d7h+3bquW9ttfb3lndz2h9uwDqNZ638ccl3RER8yR9VNIttudJWiFpQ0TMlbSheg6gS40Z9ojYFxHPVI8HJT0vabakxZLWVKutkXRji3oE0ASndM5u+wJJCyRtljQzIvZVpf2SZtbYpl9SvyRN0xl1NwqgMeO+Gm/7TEmPSbo9Il4dWYuIkBSjbRcRqyKiLyL6ejS1oWYB1G9cYbfdo+GgPxgR360WH7A9q6rPknSwNS0CaAYPH5QLK9jW8Dn5kYi4fcTyv5d0OCJW2l4hqTcivlD6WWe7Ny73NY13XYfJcy8q1pf/5w+L9e2vn1+z9pMvXFncdtqmF4r1k4PlYcNGnLxqQbH+uy/9X7G+8U/+o1j/qz1XFeu7Fx2rWYtjQ8Vtceo2xwa9GkdGHQ8dzzn7xyTdLGmb7S3VsjslrZT0qO3lkl6WdFMTegXQImOGPSKelGp+cqIzh2kAp4yPywJJEHYgCcIOJEHYgSQIO5DEmOPszdTJcfaxnPb7o37a9y27v9Vbs/b4gvuL2/7gtxcX64eOn1WsTxr9w4lvOVn4muny9w0Utz138unF+se3lkdUZ9xe/orriRdeLNbRXKVxdo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+xNMPTpvmL9YP/rxfq9lz1arF9z+tFi/aPPLqlZ+93RnuK2b/ymPMb/wc//d7GO7sI4OwDCDmRB2IEkCDuQBGEHkiDsQBKEHUiCcXZgAmGcHQBhB7Ig7EAShB1IgrADSRB2IAnCDiQxZthtz7H9Y9vP2d5h+7Zq+V2299reUt2ub327AOo1nvnZj0u6IyKesX2WpKdtr69q90bEP7SuPQDNMp752fdJ2lc9HrT9vKTZrW4MQHOd0jm77QskLZC0uVp0q+2ttlfbnlFjm37bA7YHjqn855UAtM64w277TEmPSbo9Il6V9E1JH5A0X8NH/ntG2y4iVkVEX0T09Whq4x0DqMu4wm67R8NBfzAivitJEXEgIk5ExElJ90ta2Lo2ATRqPFfjLek7kp6PiG+MWD5rxGqfkbS9+e0BaJbxXI3/mKSbJW2zvaVadqekpbbnSwpJuyR9rgX9AWiS8VyNf1IadQLwtc1vB0Cr8Ak6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEm2dstn2K5JeHrHoXEmH2tbAqenW3rq1L4ne6tXM3t4fEb83WqGtYX/Xzu2BiOjrWAMF3dpbt/Yl0Vu92tUbb+OBJAg7kESnw76qw/sv6dbeurUvid7q1ZbeOnrODqB9On1kB9AmhB1IoiNht32t7Rdsv2h7RSd6qMX2LtvbqmmoBzrcy2rbB21vH7Gs1/Z62zur+1Hn2OtQb10xjXdhmvGOvnadnv687efstidL+rWkT0raI+kpSUsj4rm2NlKD7V2S+iKi4x/AsP1xSa9J+reI+ONq2d2SjkTEyuoX5YyI+GKX9HaXpNc6PY13NVvRrJHTjEu6UdJfqIOvXaGvm9SG160TR/aFkl6MiJciYkjSI5IWd6CPrhcRGyUdecfixZLWVI/XaPg/S9vV6K0rRMS+iHimejwo6c1pxjv62hX6aotOhH22pN0jnu9Rd833HpLW2X7adn+nmxnFzIjYVz3eL2lmJ5sZxZjTeLfTO6YZ75rXrp7pzxvFBbp3WxQRH5Z0naRbqrerXSmGz8G6aex0XNN4t8so04y/pZOvXb3TnzeqE2HfK2nOiOfnV8u6QkTsre4PSvqeum8q6gNvzqBb3R/scD9v6aZpvEebZlxd8Np1cvrzToT9KUlzbV9oe4qkJZKe6EAf72J7enXhRLanS/qUum8q6ickLaseL5P0eAd7eZtumca71jTj6vBr1/HpzyOi7TdJ12v4ivz/SPpSJ3qo0ddFkn5Z3XZ0ujdJD2v4bd0xDV/bWC7pHEkbJO2U9ENJvV3U279L2iZpq4aDNatDvS3S8Fv0rZK2VLfrO/3aFfpqy+vGx2WBJLhAByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D/a5j1pJSODUgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[8].permute(1, 2, 0))\n",
    "print(y[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = 50\n",
    "\n",
    "trainer = create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] loss = 0.002301423577591777\n",
      "Learning Finished!\n",
      "[Epoch: 2] loss = 0.002060042694211006\n",
      "Learning Finished!\n",
      "[Epoch: 3] loss = 0.00443555461242795\n",
      "Learning Finished!\n",
      "[Epoch: 4] loss = 0.0023163347505033016\n",
      "Learning Finished!\n",
      "[Epoch: 5] loss = 0.002239817753434181\n",
      "Learning Finished!\n",
      "[Epoch: 6] loss = 0.002327391179278493\n",
      "Learning Finished!\n",
      "[Epoch: 7] loss = 0.0022840392775833607\n",
      "Learning Finished!\n",
      "[Epoch: 8] loss = 0.0023268393706530333\n",
      "Learning Finished!\n",
      "[Epoch: 9] loss = 0.002273962600156665\n",
      "Learning Finished!\n",
      "[Epoch: 10] loss = 0.0023027819115668535\n",
      "Learning Finished!\n",
      "[Epoch: 11] loss = 0.00231882743537426\n",
      "Learning Finished!\n",
      "[Epoch: 12] loss = 0.002242285292595625\n",
      "Learning Finished!\n",
      "[Epoch: 13] loss = 0.0022990726865828037\n",
      "Learning Finished!\n",
      "[Epoch: 14] loss = 0.0023567560128867626\n",
      "Learning Finished!\n",
      "[Epoch: 15] loss = 0.0023155990056693554\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0 # loss를 담음\n",
    "    X, Y = next(iter(test_loader)) # X: image, Y: label\n",
    "    X = X.to(device) # cuda 연산을 하기 위해 필요\n",
    "    Y = Y.to(device)\n",
    "\n",
    "    # Compute prediction and loss\n",
    "    pred = model(X) # 가설(hypothesis) H(x) = Wx + b, 예측값 prediction\n",
    "    loss = criterion(pred, Y) # loss_fn\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    avg_cost += loss / train_epoch\n",
    "    print('[Epoch: {}] loss = {}'.format(epoch+1, avg_cost))\n",
    "    print('Learning Finished!')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =    0 loss = 13749.1517\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "learning_rate = 0.005\n",
    "training_epochs = 50\n",
    "ep_log_interval = 5\n",
    "learning_rate = 0.0005\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss() # does log-softmax()\n",
    "optimizer = torch.optim.SGD(model.parameters(),learning_rate)\n",
    "model.train()\n",
    "for epoch in range(training_epochs):\n",
    "    ep_loss = 0\n",
    "    for (batch_idx, batch) in enumerate(train_loader):\n",
    "        (X, y) = batch # X = pixels, y = target labels\n",
    "        (X, y) = (X.to(device), y.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss_val = criterion(output, y) # a tensor\n",
    "        ep_loss += loss_val.item() # accumulate\n",
    "        loss_val.backward() # compute grads\n",
    "        optimizer.step()\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(\"epoch = %4d loss = %0.4f\"%(epoch, ep_loss))\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 511, 511])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = torch.Tensor(5, 3, 511, 511) # b x c x h x w\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrouse_layer = nn.Sequential(nn.Conv2d(3, 64, 7, stride=2, padding=3),\n",
    "                              nn.BatchNorm2d(64),\n",
    "                              nn.ReLU(),\n",
    "                              nn.MaxPool2d(3, 2, 1)\n",
    ")\n",
    "\n",
    "project = nn.Sequential(\n",
    "            nn.Conv2d(256, 48, 1, bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Conv2d(304, 256, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(256, 5, 1)\n",
    ")\n",
    "\n",
    "representation = nn.Sequential(\n",
    "    nn.Conv2d(304, 256, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(256, 256, 1)\n",
    ")\n",
    "\n",
    "resnet_m = resnet.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 128, 128])\n",
      "torch.Size([5, 256, 128, 128])\n",
      "prediction: \t\t torch.Size([5, 5, 128, 128])\n",
      "representation: \t torch.Size([5, 256, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "out = atrouse_layer(xx) # 5 x 64 x 128 x 128\n",
    "print(out.shape)\n",
    "\n",
    "\n",
    "#model_v3 = get_model(model_name='deeplabv3p', num_classes=5, output_dim=256)\n",
    "# encoder\n",
    "out_low = resnet_m.layer1(out)  # 5 x 256 x 128 x 128\n",
    "out = resnet_m.layer2(out_low)  # 5 x 512 x 64 x 64\n",
    "out = resnet_m.layer3(out)      # 5 x 1024 x 32 x 32\n",
    "out = resnet_m.layer4(out)      # 5 x 2048 x 16 x 16\n",
    "feature = ASPP(2048, [6, 12, 18])(out) # 5 x 256 x 16 x 16\n",
    "\n",
    "# decoder\n",
    "out_low = project(out_low) # 5 x 48 x 128 x 128\n",
    "# interpolate: 작은 feature의 크기를 크게 변경시킬 때 사용됨(upsampling)\n",
    "output_feature = F.interpolate(feature, size=out_low.shape[2:], mode='bilinear', align_corners=True)\n",
    "# 5 x 256 x 128 x 128\n",
    "print(output_feature.shape)\n",
    "prediction = classifier(torch.cat([out_low, output_feature], dim =1 )) # 5 x 5 x 128 x 128\n",
    "rep = representation(torch.cat([out_low, output_feature], dim=1))  # 5 x 256 x 128 x 128\n",
    "print(\"prediction: \\t\\t\", prediction.shape)\n",
    "print(\"representation: \\t\", rep.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\imgseg\\lib\\site-packages\\torchvision\\transforms\\functional.py:404: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable builtin_function_or_method object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\OneDrive\\C Documents\\GitHub\\ImageClassification\\baseline\\torch_mnist_test.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/OneDrive/C%20Documents/GitHub/ImageClassification/baseline/torch_mnist_test.ipynb#ch0000024?line=0'>1</a>\u001b[0m datasets\u001b[39m.\u001b[39;49mtransform(xx)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\OneDrive\\C Documents\\GitHub\\ImageClassification\\baseline\\modules\\datasets.py:24\u001b[0m, in \u001b[0;36mtransform\u001b[1;34m(image, label, logits, crop_size, scale_size, augmentation)\u001b[0m\n\u001b[0;32m     21\u001b[0m     logits \u001b[39m=\u001b[39m transforms_f\u001b[39m.\u001b[39mresize(logits, (\u001b[39m385\u001b[39m, \u001b[39m513\u001b[39m), Image\u001b[39m.\u001b[39mNEAREST)\n\u001b[0;32m     23\u001b[0m \u001b[39m# Random rescale image\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m raw_w, raw_h \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39msize\n\u001b[0;32m     25\u001b[0m scale_ratio \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39muniform(scale_size[\u001b[39m0\u001b[39m], scale_size[\u001b[39m1\u001b[39m])  \u001b[39m# random scale size (0.8<= i <= 1.0)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m resized_size \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m(raw_h \u001b[39m*\u001b[39m scale_ratio), \u001b[39mint\u001b[39m(raw_w \u001b[39m*\u001b[39m scale_ratio))\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable builtin_function_or_method object"
     ]
    }
   ],
   "source": [
    "datasets.transform(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "pool = nn.MaxPool2d(2)\n",
    "fc = nn.Linear(3136, 10)\n",
    "relu = nn.ReLU()\n",
    "relu_in = nn.ReLU(True)\n",
    "bn1 = nn.BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (Tensor, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\GitHub\\ImageClassification\\torch_mnist_test.ipynb Cell 21'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/ImageClassification/torch_mnist_test.ipynb#ch0000019?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m conv1(xx) \u001b[39m# 1, 32, 28 x 28\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/ImageClassification/torch_mnist_test.ipynb#ch0000019?line=1'>2</a>\u001b[0m out \u001b[39m=\u001b[39m bn1(out)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/ImageClassification/torch_mnist_test.ipynb#ch0000019?line=2'>3</a>\u001b[0m out \u001b[39m=\u001b[39m relu_in(out)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/ImageClassification/torch_mnist_test.ipynb#ch0000019?line=4'>5</a>\u001b[0m out \u001b[39m=\u001b[39m pool(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\batchnorm.py:130\u001b[0m, in \u001b[0;36m_BatchNorm.__init__\u001b[1;34m(self, num_features, eps, momentum, affine, track_running_stats, device, dtype)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    120\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    121\u001b[0m     num_features,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    128\u001b[0m ):\n\u001b[0;32m    129\u001b[0m     factory_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: device, \u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m: dtype}\n\u001b[1;32m--> 130\u001b[0m     \u001b[39msuper\u001b[39m(_BatchNorm, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    131\u001b[0m         num_features, eps, momentum, affine, track_running_stats, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs\n\u001b[0;32m    132\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\batchnorm.py:45\u001b[0m, in \u001b[0;36m_NormBase.__init__\u001b[1;34m(self, num_features, eps, momentum, affine, track_running_stats, device, dtype)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrack_running_stats \u001b[39m=\u001b[39m track_running_stats\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maffine:\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(num_features, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m     46\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(num_features, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (Tensor, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "out = conv1(xx) # 1, 32, 28 x 28\n",
    "out = bn1(out)\n",
    "out = relu_in(out)\n",
    "\n",
    "out = pool(out)\n",
    "out = conv2(out) # 32, 64, 28 x 28\n",
    "out = pool(out) # maxpool 2, b x 64 x 14 x 14\n",
    "out = pool(out) # maxpool 2, b x 64 x 7 x 7\n",
    "out = out.view(out.size(0), -1) # b x 3136\n",
    "out = fc(out)\n",
    "\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#ch0000007untitled?line=0'>1</a>\u001b[0m out[\u001b[39m1\u001b[39;49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'annotations' could not be imported from 'c:\\Users\\PiusHwang\\Anaconda3\\envs\\aicomp\\Lib\\site-packages\\torch\\__future__.py'.\n",
      "Click <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "X_train = DataLoader(mnist_train, 5, shuffle=True, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
