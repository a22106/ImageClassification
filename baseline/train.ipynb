{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\imgseg\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modules.utils import load_yaml, save_yaml, get_logger, str2bool\n",
    "from modules.earlystoppers import EarlyStopper\n",
    "from modules.recorders import Recorder\n",
    "from modules.datasets import *\n",
    "from modules.trainer import Trainer\n",
    "from modules.optimizers import get_optimizer\n",
    "from modules.schedulers import PolyLR\n",
    "from models.utils import get_model, EMA\n",
    "import torch\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Semi-supervised Segmentation for AICompetition')\n",
    "# parser.add_argument('--is_trained', help='boolean flag', default=False, type=str2bool)\n",
    "# parser.add_argument('--is_colab', help='boolean flag', default=False, type=str2bool)\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220617_112400\n"
     ]
    }
   ],
   "source": [
    "# Root directory\n",
    "__file__ = './'\n",
    "PROJECT_DIR = os.path.dirname(__file__)\n",
    "GDRIVE_DIR = '/content/drive/MyDrive'\n",
    "\n",
    "# Load config\n",
    "config_path = os.path.join(PROJECT_DIR, 'config', 'train_config.yml')\n",
    "config = load_yaml(config_path)\n",
    "\n",
    "# is_trained = args.is_trained\n",
    "# if is_trained == True:\n",
    "is_trained = False\n",
    "if is_trained == True:\n",
    "      pre_config = config\n",
    "      is_trained = config['TRAINER']['is_trained']\n",
    "      train_serial = config['TRAINER']['train_serial']\n",
    "      config = load_yaml(os.path.join(PROJECT_DIR, 'results', 'train', train_serial, 'train_config.yml'))\n",
    "#elif args.is_trained == False:\n",
    "elif is_trained == False:\n",
    "    # Train Serial\n",
    "    is_trained = False\n",
    "    kst = timezone(timedelta(hours=9))\n",
    "    train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(train_serial)\n",
    "\n",
    "\n",
    "# Recorder directory\n",
    "#if args.is_colab == True:\n",
    "is_colab = False\n",
    "if is_colab == True:\n",
    "    RECORDER_DIR = os.path.join(GDRIVE_DIR, 'results', 'train', train_serial)\n",
    "else:\n",
    "    RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n",
    "os.makedirs(RECORDER_DIR, exist_ok=True)\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data', config['DIRECTORY']['dataset'])\n",
    "\n",
    "# Seed\n",
    "torch.manual_seed(config['TRAINER']['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(config['TRAINER']['seed'])\n",
    "random.seed(config['TRAINER']['seed'])\n",
    "\n",
    "# GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(config['TRAINER']['gpu'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "00. Set Logger\n",
    "\"\"\"\n",
    "logger = get_logger(name='train', dir_=RECORDER_DIR, stream=False)\n",
    "logger.info(f\"Set Logger {RECORDER_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "01. Load data\n",
    "\"\"\"\n",
    "# Dataset\n",
    "data_loader = BuildDataLoader(num_labels=config['MODEL']['num_labels'], dataset_path=config['DIRECTORY']['dataset'],\n",
    "                                batch_size=config['DATALOADER']['batch_size'])\n",
    "train_l_loader, train_u_loader, valid_l_loader, _ = data_loader.build(supervised=False)\n",
    "print(len(train_l_loader))\n",
    "print(len(train_u_loader))\n",
    "logger.info(f\"Load data, train (labeled):{len(train_l_loader)} train (unlabeled):{len(train_u_loader)} val:{len(valid_l_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "02. Set model\n",
    "\"\"\"\n",
    "# Load model\n",
    "model = get_model(model_name=config['TRAINER']['model'],num_classes=config['MODEL']['num_labels'],\n",
    "                    output_dim=config['MODEL']['output_dim']).to(device)\n",
    "ema = EMA(model, 0.99)  # Mean teacher model\n",
    "\n",
    "\"\"\"\n",
    "03. Set trainer\n",
    "\"\"\"\n",
    "# Optimizer\n",
    "optimizer = get_optimizer(optimizer_name=config['TRAINER']['optimizer'])\n",
    "optimizer = optimizer(params=model.parameters(),lr=config['TRAINER']['learning_rate'])\n",
    "scheduler = PolyLR(optimizer, config['TRAINER']['n_epochs'], power=0.9)\n",
    "\n",
    "# Early stoppper\n",
    "early_stopper = EarlyStopper(patience=config['TRAINER']['early_stopping_patience'],\n",
    "                            mode=config['TRAINER']['early_stopping_mode'],\n",
    "                            logger=logger)\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(model=model,\n",
    "                    ema=ema,\n",
    "                    data_loader=data_loader,\n",
    "                    optimizer=optimizer,\n",
    "                    device=device,\n",
    "                    logger=logger,\n",
    "                    config=config['TRAINER'],\n",
    "                    interval=config['LOGGER']['logging_interval'])\n",
    "\n",
    "\"\"\"\n",
    "Logger\n",
    "\"\"\"\n",
    "# Recorder\n",
    "recorder = Recorder(record_dir=RECORDER_DIR,\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    logger=logger)\n",
    "\n",
    "# !Wandb\n",
    "if config['LOGGER']['wandb'] == True: ## 사용시 본인 wandb 계정 입력\n",
    "    wandb_project_serial = 'v3p_adamw_classmix'\n",
    "    wandb_username = 'a22106'\n",
    "    wandb.init(project=wandb_project_serial, dir=RECORDER_DIR, entity=wandb_username)\n",
    "    wandb.run.name = train_serial\n",
    "    wandb.config.update(config)\n",
    "    wandb.watch(model)\n",
    "\n",
    "# Save train config\n",
    "save_yaml(os.path.join(RECORDER_DIR, 'train_config.yml'), config)\n",
    "\n",
    "\"\"\"\n",
    "04. TRAIN\n",
    "\"\"\"\n",
    "# Train\n",
    "# set epoch\n",
    "n_epochs = config['TRAINER']['n_epochs']\n",
    "if is_trained:\n",
    "    pre_record_csv = pd.read_csv(os.path.join(PROJECT_DIR, 'results', 'train', train_serial, 'record.csv'))\n",
    "    pre_epoch = list(pre_record_csv['epoch_index'])[-1] +1\n",
    "else:\n",
    "    pre_epoch = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('imgseg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d845fd51fc75d2ae1670e74f4f446c0d06dfba8d4cc9ca0062c740d6c529ae66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
