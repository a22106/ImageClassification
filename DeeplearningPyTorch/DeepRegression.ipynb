{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Regression\n",
    "\n",
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PiusHwang\\Anaconda3\\envs\\aicomp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 라이브러리 및 데이터를 불러옴. \n",
    "출력 값은 TARGET 속성으로 저장되도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보스턴 주택 가격 데이터셋 구성\n",
    "* 13개의 속성과 506개의 샘플로 구성됨\n",
    "* 성능 향상, 수월한 최적화를 위해 표준 스케일링(Standard Scailng)을 통해 입력값 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df.values[:, :-1])\n",
    "df.values[:, :-1] = scaler.transform(df.values[:, :-1]).round(4) \n",
    "# round(4)는 소숫점 4자리 밑은 반올림 하겠다는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.4198</td>\n",
       "      <td>0.2848</td>\n",
       "      <td>-1.2879</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>-0.1442</td>\n",
       "      <td>0.4137</td>\n",
       "      <td>-0.1200</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.6666</td>\n",
       "      <td>-1.4590</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>-1.0756</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.4173</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>-0.5934</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>-0.7403</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.3672</td>\n",
       "      <td>0.5572</td>\n",
       "      <td>-0.8679</td>\n",
       "      <td>-0.9873</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>-0.4924</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.4173</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>-0.5934</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>-0.7403</td>\n",
       "      <td>1.2827</td>\n",
       "      <td>-0.2658</td>\n",
       "      <td>0.5572</td>\n",
       "      <td>-0.8679</td>\n",
       "      <td>-0.9873</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>-1.2087</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.4168</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>-1.3069</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>-0.8353</td>\n",
       "      <td>1.0163</td>\n",
       "      <td>-0.8099</td>\n",
       "      <td>1.0777</td>\n",
       "      <td>-0.7529</td>\n",
       "      <td>-1.1061</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.4162</td>\n",
       "      <td>-1.3615</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.4125</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>-1.3069</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>-0.8353</td>\n",
       "      <td>1.2286</td>\n",
       "      <td>-0.5112</td>\n",
       "      <td>1.0777</td>\n",
       "      <td>-0.7529</td>\n",
       "      <td>-1.1061</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>-1.0265</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.4132</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.4393</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>-0.6258</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.3872</td>\n",
       "      <td>-0.4181</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.4152</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>-0.2345</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>-0.7166</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>-0.5008</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.4134</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>-0.7737</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>-0.9830</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>-0.4078</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>-0.6684</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>-0.8653</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.4150</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>-0.2726</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>-0.3628</td>\n",
       "      <td>0.4347</td>\n",
       "      <td>-0.6132</td>\n",
       "      <td>-0.9828</td>\n",
       "      <td>-0.8032</td>\n",
       "      <td>1.1765</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>-0.6691</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM      ZN   INDUS    CHAS     NOX      RM     AGE     DIS     RAD  \\\n",
       "0   -0.4198  0.2848 -1.2879 -0.2726 -0.1442  0.4137 -0.1200  0.1402 -0.9828   \n",
       "1   -0.4173 -0.4877 -0.5934 -0.2726 -0.7403  0.1943  0.3672  0.5572 -0.8679   \n",
       "2   -0.4173 -0.4877 -0.5934 -0.2726 -0.7403  1.2827 -0.2658  0.5572 -0.8679   \n",
       "3   -0.4168 -0.4877 -1.3069 -0.2726 -0.8353  1.0163 -0.8099  1.0777 -0.7529   \n",
       "4   -0.4125 -0.4877 -1.3069 -0.2726 -0.8353  1.2286 -0.5112  1.0777 -0.7529   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "501 -0.4132 -0.4877  0.1157 -0.2726  0.1581  0.4393  0.0187 -0.6258 -0.9828   \n",
       "502 -0.4152 -0.4877  0.1157 -0.2726  0.1581 -0.2345  0.2889 -0.7166 -0.9828   \n",
       "503 -0.4134 -0.4877  0.1157 -0.2726  0.1581  0.9850  0.7974 -0.7737 -0.9828   \n",
       "504 -0.4078 -0.4877  0.1157 -0.2726  0.1581  0.7257  0.7370 -0.6684 -0.9828   \n",
       "505 -0.4150 -0.4877  0.1157 -0.2726  0.1581 -0.3628  0.4347 -0.6132 -0.9828   \n",
       "\n",
       "        TAX  PTRATIO       B   LSTAT  target  \n",
       "0   -0.6666  -1.4590  0.4411 -1.0756    24.0  \n",
       "1   -0.9873  -0.3031  0.4411 -0.4924    21.6  \n",
       "2   -0.9873  -0.3031  0.3964 -1.2087    34.7  \n",
       "3   -1.1061   0.1130  0.4162 -1.3615    33.4  \n",
       "4   -1.1061   0.1130  0.4411 -1.0265    36.2  \n",
       "..      ...      ...     ...     ...     ...  \n",
       "501 -0.8032   1.1765  0.3872 -0.4181    22.4  \n",
       "502 -0.8032   1.1765  0.4411 -0.5008    20.6  \n",
       "503 -0.8032   1.1765  0.4411 -0.9830    23.9  \n",
       "504 -0.8032   1.1765  0.4032 -0.8653    22.0  \n",
       "505 -0.8032   1.1765  0.4411 -0.6691    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정규화(regression)을 하는 이유는 날 것 그대로의 값을 활용하여 학습을 수행하기위함\n",
    "* 이러한 경우 각 col의 값이 다른 범위와 분포를 갖기 때문에 신경망이 이것을 학습할 떄 어려움을 겪을 수 있음.\n",
    "* 잘 학습된 신경망에서는 이러한 각 열의 특징에 따라 알맞은 계수(coefficient)곱해주어 상쇄가능하지만, 처음 학습하는 신경망 입장에서는 잘 정규화된 데이터셋을 배우는 것에 비해 어려운 일이 될 수 있음\n",
    "* 적절한 <font color='red'>**정규화(Regression) 과정**</font>을 통해 신경망의 최적화를 수월하게 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화 방법\n",
    "* 표준 스케일링(Standard Scailing), 최소/최대 스케일링(min/max Scailing) 등\n",
    "* 정규화를 적용하기에 앞서 데이터셋 분포의 특징을 파악하고 어떤 정규화 방법을 사용할지 결정해야 함\n",
    "* 보스턴 주택 가격 데이터셋의 각 열이 정규 분포(normal distribution)를 따른다고 가정하고 표준 스케일링을 적용함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PiusHwang\\Anaconda3\\envs\\aicomp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(df.values).float()\n",
    "x = data[:, :-1].to(device)\n",
    "y = data[:, -1:].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200000\n",
    "learning_rate = 1e-4\n",
    "print_interval = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 심층 신경망(Deep Neural Network) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x.size(-1)\n",
    "output_dim = y.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDNN(\n",
      "  (linear1): Linear(in_features=13, out_features=3, bias=True)\n",
      "  (linear2): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (linear3): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (linear4): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (act): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyDNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        super(MyDNN, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(self.input_dim, 3)\n",
    "        self.linear2 = nn.Linear(3, 3)\n",
    "        self.linear3 = nn.Linear(3, 3)\n",
    "        self.linear4 = nn.Linear(3, output_dim)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.linear1(x))\n",
    "        h = self.act(self.linear2(h))\n",
    "        h = self.act(self.linear3(h))\n",
    "        y = self.linear4(h) # y = (batch_size, output_dim)\n",
    "        \n",
    "        return y\n",
    "\n",
    "model = MyDNN(input_dim, output_dim).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 503, 3]              42\n",
      "              ReLU-2               [-1, 503, 3]               0\n",
      "            Linear-3               [-1, 503, 3]              12\n",
      "              ReLU-4               [-1, 503, 3]               0\n",
      "            Linear-5               [-1, 503, 3]              12\n",
      "              ReLU-6               [-1, 503, 3]               0\n",
      "            Linear-7               [-1, 503, 1]               4\n",
      "================================================================\n",
      "Total params: 70\n",
      "Trainable params: 70\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.07\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (503, 13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다른 모델 구성 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(x.size(-1), 3),\n",
    "    nn.LeakyReLU(negative_slope=0.01),\n",
    "    nn.Linear(3, 3),\n",
    "    nn.LeakyReLU(negative_slope=0.01),\n",
    "    nn.Linear(3, 3),\n",
    "    nn.LeakyReLU(negative_slope=0.01),\n",
    "    nn.Linear(3, 3),\n",
    "    nn.LeakyReLU(negative_slope=0.01),\n",
    "    nn.Linear(3, 1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 506, 3]              42\n",
      "         LeakyReLU-2               [-1, 506, 3]               0\n",
      "            Linear-3               [-1, 506, 3]              12\n",
      "         LeakyReLU-4               [-1, 506, 3]               0\n",
      "            Linear-5               [-1, 506, 3]              12\n",
      "         LeakyReLU-6               [-1, 506, 3]               0\n",
      "            Linear-7               [-1, 506, 3]              12\n",
      "         LeakyReLU-8               [-1, 506, 3]               0\n",
      "            Linear-9               [-1, 506, 1]               4\n",
      "================================================================\n",
      "Total params: 82\n",
      "Trainable params: 82\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.10\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoches: 10000/200000, loss: 9.5258\n",
      "epoches: 20000/200000, loss: 9.0664\n",
      "epoches: 30000/200000, loss: 9.0072\n",
      "epoches: 40000/200000, loss: 8.7815\n",
      "epoches: 50000/200000, loss: 8.7352\n",
      "epoches: 60000/200000, loss: 8.7265\n",
      "epoches: 70000/200000, loss: 8.7188\n",
      "epoches: 80000/200000, loss: 8.7104\n",
      "epoches: 90000/200000, loss: 8.7003\n",
      "epoches: 100000/200000, loss: 8.6009\n",
      "epoches: 110000/200000, loss: 8.4997\n",
      "epoches: 120000/200000, loss: 8.4801\n",
      "epoches: 130000/200000, loss: 8.4751\n",
      "epoches: 140000/200000, loss: 8.4731\n",
      "epoches: 150000/200000, loss: 8.4720\n",
      "epoches: 160000/200000, loss: 8.4713\n",
      "epoches: 170000/200000, loss: 8.4704\n",
      "epoches: 180000/200000, loss: 8.4698\n",
      "epoches: 190000/200000, loss: 8.4693\n",
      "epoches: 200000/200000, loss: 8.4687\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    y_hat = model(x)\n",
    "    loss = F.mse_loss(y_hat,y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if (i + 1) % print_interval == 0:\n",
    "        print('epoches: {}/{}, loss: {:.4f}'.format(i+1, n_epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x234c3302b20>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\GitHub\\ImageClassification\\DeeplearningPyTorch\\DeepRegression.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/ImageClassification/DeeplearningPyTorch/DeepRegression.ipynb#ch0000029?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(torch\u001b[39m.\u001b[39;49mcat([y, y_hat], dim \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mto(device), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my_hat\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/ImageClassification/DeeplearningPyTorch/DeepRegression.ipynb#ch0000029?line=2'>3</a>\u001b[0m sns\u001b[39m.\u001b[39mpairplot(df, height \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/ImageClassification/DeeplearningPyTorch/DeepRegression.ipynb#ch0000029?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(torch.cat([y, y_hat], dim = 1).detach().numpy().to(device), columns=['y', 'y_hat'])\n",
    "\n",
    "sns.pairplot(df, height = 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('aicomp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca3cd20c8ed94420af4701aa4e5766dbc68c4ea6bc8409f5f338bc464fc401d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
