{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import network\n",
    "import utils\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils import data\n",
    "#from datasets import VOCSegmentation, Cityscapes\n",
    "#from utils import ext_transforms as et\n",
    "#from metrics import StreamSegMetrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from utils.visualizer import Visualizer\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import yaml\n",
    "from datetime import datetime, timezone, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_harbor_idx(data_path, train = True, is_label = False, label_num = 5):\n",
    "    if train:\n",
    "        if is_label:\n",
    "            classes = ['ship', 'container_truck', 'forklift', 'reach_stacker']\n",
    "            image_path = glob(os.path.join(root, 'train', 'labeled_images', '*.jpg'))\n",
    "            image_idx_list = list(map(lambda x : x.split('/')[-1].split('.')[0], image_path))\n",
    "            train_idx = []\n",
    "            valid_idx = []\n",
    "            for c in classes:\n",
    "                matched_idx = [i for i in image_idx_list if c in i]\n",
    "                train_idx.extend(matched_idx[label_num:])\n",
    "                valid_idx.extend(matched_idx[:label_num])\n",
    "            return train_idx, valid_idx\n",
    "        else:\n",
    "            image_path = glob(os.path.join(root, 'train', 'unlabeled_images', '*.jpg'))\n",
    "            train_idx = list(map(lambda x: x.split('/')[-1].split('.')[0], image_path))\n",
    "            return train_idx\n",
    "    else:\n",
    "        image_path = glob(os.path.join(root, 'test', 'images', '*.jpg'))\n",
    "        test_idx = list(map(lambda x: x.split('/')[-1].split('.')[0], image_path))\n",
    "        return test_idx\n",
    "\n",
    "\n",
    "\n",
    "class BuildDataLoader:\n",
    "    def __init__(self, num_labels, dataset_path, batch_size):\n",
    "        self.data_path = dataset_path\n",
    "        self.im_size = [513, 513]\n",
    "        self.crop_size = [430, 430]\n",
    "        self.num_segments = 5\n",
    "        self.scale_size = (0.5, 1.5)\n",
    "        self.batch_size = batch_size\n",
    "        self.train_l_idx, self.valid_l_idx = get_harbor_idx(self.data_path, train=True, is_label=True, label_num=num_labels)\n",
    "        self.train_u_idx = get_harbor_idx(self.data_path, train=True, is_label=False)\n",
    "        self.test_idx = get_harbor_idx(self.data_path, train=False)\n",
    "\n",
    "        if num_labels == 0:  # using all data\n",
    "            self.train_l_idx = self.train_u_idx\n",
    "\n",
    "    def build(self, supervised=False):\n",
    "        train_l_dataset = BuildDataset(self.data_path, self.train_l_idx,\n",
    "                                       crop_size=self.crop_size, scale_size=self.scale_size,\n",
    "                                       augmentation=True, train=True, is_label=True)\n",
    "        train_u_dataset = BuildDataset(self.data_path, self.train_u_idx,\n",
    "                                       crop_size=self.crop_size, scale_size=(1.0, 1.0),\n",
    "                                       augmentation=False, train=True, is_label=False)\n",
    "        valid_l_dataset = BuildDataset(self.data_path, self.valid_l_idx,\n",
    "                                       crop_size=self.crop_size, scale_size=self.scale_size,\n",
    "                                       augmentation=False, train=True, is_label=True)\n",
    "        test_dataset    = BuildDataset(self.data_path, self.test_idx,\n",
    "                                       crop_size=self.im_size, scale_size=(1.0, 1.0),\n",
    "                                       augmentation=False, train=False, is_label=True)\n",
    "\n",
    "        if supervised:  # no unlabelled dataset needed, double batch-size to match the same number of training samples\n",
    "            self.batch_size = self.batch_size * 2\n",
    "\n",
    "        num_samples = self.batch_size * 200  # for total 40k iterations with 200 epochs\n",
    "        # num_samples = self.batch_size * 2\n",
    "        train_l_loader = torch.utils.data.DataLoader(\n",
    "            train_l_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=sampler.RandomSampler(data_source=train_l_dataset,\n",
    "                                          replacement=True,\n",
    "                                          num_samples=num_samples),\n",
    "            drop_last=True,)\n",
    "\n",
    "\n",
    "        valid_l_loader = torch.utils.data.DataLoader(\n",
    "            valid_l_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=sampler.RandomSampler(data_source=valid_l_dataset,\n",
    "                                          replacement=True,\n",
    "                                          num_samples=num_samples),\n",
    "            drop_last=True,)\n",
    "\n",
    "        if not supervised:\n",
    "            train_u_loader = torch.utils.data.DataLoader(\n",
    "                train_u_dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                sampler=sampler.RandomSampler(data_source=train_u_dataset,\n",
    "                                              replacement=True,\n",
    "                                              num_samples=num_samples),\n",
    "                drop_last=True,)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        if supervised:\n",
    "            return train_l_loader, valid_l_loader, test_loader\n",
    "        else:\n",
    "            return train_l_loader, train_u_loader, valid_l_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from collections import namedtuple\n",
    "\n",
    "class Comp_dataset(data.Dataset):\n",
    "    DatasetClass = namedtuple('DataClass', ['name', 'id'])\n",
    "    classes = [\n",
    "        DatasetClass('unlabeled', 0),\n",
    "        DatasetClass('container_truck', 1),\n",
    "        DatasetClass('forklift', 2),\n",
    "        DatasetClass('reach_stacker', 3),\n",
    "        DatasetClass('ship', 4)\n",
    "    ]\n",
    "\n",
    "    id_to_train_id = np.array([c.train_id for c in classes])\n",
    "\n",
    "    def __init__(self, root, split = 'train', transform = None):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.image_dir = os.path.join(self.root, 'data', split)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.split = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    train_transform = extcompose([])\n",
    "\n",
    "    train_dataset = Comp_dataset(root=, split=, transform=)\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (477171462.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [9]\u001b[1;36m\u001b[0m\n\u001b[1;33m    metrics =\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Root directory\n",
    "PROJECT_DIR = os.path.dirname(__file__)\n",
    "\n",
    "# Load config\n",
    "config_path = os.path.join(PROJECT_DIR, 'config', 'train_config.yml')\n",
    "config = load_yaml(config_path)\n",
    "\n",
    "# Train Serial\n",
    "kst = timezone(timedelta(hours=9))\n",
    "train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Recorder directory\n",
    "RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n",
    "os.makedirs(RECORDER_DIR, exist_ok=True)\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data', config['DIRECTORY']['dataset'])\n",
    "\n",
    "# GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config['gpu_id']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "# Setup random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Setup dataloader\n",
    "batch_size = 5\n",
    "\n",
    "train_dataset, valid_dataset = get_dataset(config)\n",
    "data_loader = BuildDataLoader(num_labels = 5, dataset_path = \"\", batch_size = 5)\n",
    "\n",
    "\n",
    "train_l_loader, train_u_loader, valid_l_loader, _ = data_loader.build()\n",
    "print(\"Train set: {}, train unsup set: {}, Val set: {}\".format(len(train_l_loader), len(train_u_loader), len(valid_l_loader)))\n",
    "\n",
    "\n",
    "####\n",
    "#set up model (all models are 'constructed at network.modeling)\n",
    "model = network.modeling.__dict__[config['model'](num_classes = num_classes, output_stride = config['output_stride'])]\n",
    "\n",
    "#####\n",
    "#set up metrics\n",
    "metrics = \n",
    "    \n",
    "#####\n",
    "#set up optimizer\n",
    "optimizer = torch.optim.SGD()  \n",
    "if config['lr_policy'] == 'poly':\n",
    "    scheduler = PolyLR\n",
    "elif config['lr_policy'] == 'step':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['step_size'], gamma=0.1)\n",
    "\n",
    "\n",
    "######\n",
    "#set up criterion\n",
    "# criterion = utils.get_loss(config['loss_type'])\n",
    "if config['loss_type'] == 'focal_loss':\n",
    "    criterion = utils.FocalLoss(ignore_index = 255, size_average = True)\n",
    "elif config['loss_type'] == 'cross_entropy':\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=255, reduction = 'mean')\n",
    "\n",
    "def save_ckpt(path):\n",
    "    \"\"\"save current model\"\"\"\n",
    "    torch.save()\n",
    "    print(\"Model saved as {}\".format(path))\n",
    "\n",
    "mkdir('checkpoints')\n",
    "\n",
    "# Restore\n",
    "best_score == 0.0\n",
    "cur_itrs = 0\n",
    "cur_epochs = 0\n",
    "if config['ckpt'] not None and os.path.isfile(config['ckpt']): # if checkpoint is available\n",
    "    checkpoint = torch.load(config['ckpt'], map_location = torch.device['cpu'])\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "else:\n",
    "    print(\"[!] Retrain\")\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "# train Loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('aicomp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca3cd20c8ed94420af4701aa4e5766dbc68c4ea6bc8409f5f338bc464fc401d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
