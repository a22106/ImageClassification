{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "import network\n",
    "from network.deeplabv3 import DeepLabv3Plus\n",
    "import utils\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils import data\n",
    "#from datasets import VOCSegmentation, Cityscapes\n",
    "#from utils import ext_transforms as et\n",
    "#from metrics import StreamSegMetrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "#from utils.visualizer import Visualizer\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import yaml\n",
    "from datetime import datetime, timezone, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_harbor_idx(data_path, train = True, is_label = False, label_num = 5):\n",
    "    if train:\n",
    "        if is_label:\n",
    "            classes = ['ship', 'container_truck', 'forklift', 'reach_stacker']\n",
    "            image_path = glob(os.path.join(root, 'train', 'labeled_images', '*.jpg'))\n",
    "            image_idx_list = list(map(lambda x : x.split('/')[-1].split('.')[0], image_path))\n",
    "            train_idx = []\n",
    "            valid_idx = []\n",
    "            for c in classes:\n",
    "                matched_idx = [i for i in image_idx_list if c in i]\n",
    "                train_idx.extend(matched_idx[label_num:])\n",
    "                valid_idx.extend(matched_idx[:label_num])\n",
    "            return train_idx, valid_idx\n",
    "        else:\n",
    "            image_path = glob(os.path.join(root, 'train', 'unlabeled_images', '*.jpg'))\n",
    "            train_idx = list(map(lambda x: x.split('/')[-1].split('.')[0], image_path))\n",
    "            return train_idx\n",
    "    else:\n",
    "        image_path = glob(os.path.join(root, 'test', 'images', '*.jpg'))\n",
    "        test_idx = list(map(lambda x: x.split('/')[-1].split('.')[0], image_path))\n",
    "        return test_idx\n",
    "\n",
    "\n",
    "\n",
    "class BuildDataLoader:\n",
    "    def __init__(self, num_labels, dataset_path, batch_size):\n",
    "        self.data_path = dataset_path\n",
    "        self.im_size = [513, 513]\n",
    "        self.crop_size = [430, 430]\n",
    "        self.num_segments = 5\n",
    "        self.scale_size = (0.5, 1.5)\n",
    "        self.batch_size = batch_size\n",
    "        self.train_l_idx, self.valid_l_idx = get_harbor_idx(self.data_path, train=True, is_label=True, label_num=num_labels)\n",
    "        self.train_u_idx = get_harbor_idx(self.data_path, train=True, is_label=False)\n",
    "        self.test_idx = get_harbor_idx(self.data_path, train=False)\n",
    "\n",
    "        if num_labels == 0:  # using all data\n",
    "            self.train_l_idx = self.train_u_idx\n",
    "\n",
    "    def build(self, supervised=False):\n",
    "        train_l_dataset = BuildDataset(self.data_path, self.train_l_idx,\n",
    "                                       crop_size=self.crop_size, scale_size=self.scale_size,\n",
    "                                       augmentation=True, train=True, is_label=True)\n",
    "        train_u_dataset = BuildDataset(self.data_path, self.train_u_idx,\n",
    "                                       crop_size=self.crop_size, scale_size=(1.0, 1.0),\n",
    "                                       augmentation=False, train=True, is_label=False)\n",
    "        valid_l_dataset = BuildDataset(self.data_path, self.valid_l_idx,\n",
    "                                       crop_size=self.crop_size, scale_size=self.scale_size,\n",
    "                                       augmentation=False, train=True, is_label=True)\n",
    "        test_dataset    = BuildDataset(self.data_path, self.test_idx,\n",
    "                                       crop_size=self.im_size, scale_size=(1.0, 1.0),\n",
    "                                       augmentation=False, train=False, is_label=True)\n",
    "\n",
    "        if supervised:  # no unlabelled dataset needed, double batch-size to match the same number of training samples\n",
    "            self.batch_size = self.batch_size * 2\n",
    "\n",
    "        num_samples = self.batch_size * 200  # for total 40k iterations with 200 epochs\n",
    "        # num_samples = self.batch_size * 2\n",
    "        train_l_loader = torch.utils.data.DataLoader(\n",
    "            train_l_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=sampler.RandomSampler(data_source=train_l_dataset,\n",
    "                                          replacement=True,\n",
    "                                          num_samples=num_samples),\n",
    "            drop_last=True,)\n",
    "\n",
    "\n",
    "        valid_l_loader = torch.utils.data.DataLoader(\n",
    "            valid_l_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=sampler.RandomSampler(data_source=valid_l_dataset,\n",
    "                                          replacement=True,\n",
    "                                          num_samples=num_samples),\n",
    "            drop_last=True,)\n",
    "\n",
    "        if not supervised:\n",
    "            train_u_loader = torch.utils.data.DataLoader(\n",
    "                train_u_dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                sampler=sampler.RandomSampler(data_source=train_u_dataset,\n",
    "                                              replacement=True,\n",
    "                                              num_samples=num_samples),\n",
    "                drop_last=True,)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        if supervised:\n",
    "            return train_l_loader, valid_l_loader, test_loader\n",
    "        else:\n",
    "            return train_l_loader, train_u_loader, valid_l_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from collections import namedtuple\n",
    "\n",
    "class Comp_dataset(data.Dataset):\n",
    "    DatasetClass = namedtuple('DataClass', ['name', 'id'])\n",
    "    classes = [\n",
    "        DatasetClass('unlabeled', 0),\n",
    "        DatasetClass('container_truck', 1),\n",
    "        DatasetClass('forklift', 2),\n",
    "        DatasetClass('reach_stacker', 3),\n",
    "        DatasetClass('ship', 4)\n",
    "    ]\n",
    "\n",
    "    id_to_train_id = np.array([c.train_id for c in classes])\n",
    "\n",
    "    def __init__(self, root, transform = None):\n",
    "        # Base directory\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.image_dir = os.path.join(self.root, 'data')\n",
    "        self.num_classes = 5\n",
    "        self.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    train_transform = extcompose([])\n",
    "\n",
    "    train_dataset = Comp_dataset(root=, split=, transform=)\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_yaml(path, obj):\n",
    "\twith open(path, 'w') as f:\n",
    "\t\tyaml.dump(obj, f, sort_keys=False)\n",
    "\t\t\n",
    "\n",
    "def load_yaml(path):\n",
    "\twith open(path, 'r', encoding='utf-8') as f:\n",
    "\t\treturn yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\imgseg\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "# from modeling.backbone import resnet\n",
    "\n",
    "model_urls = {'resnet101': \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\"}\n",
    "\n",
    "# Conv parameters = Kernel size x Kernel Size x Input Channel x Output Channel\n",
    "# BottleNeck is 1x1 Conv: 1 x 1 x Input Channel x Output Channel\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride = 1, dilation=1, downsample=None, BatchNorm=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=stride, dilation=dilation,\n",
    "            padding=dilation, bias=False,\n",
    "        )\n",
    "        self.bn2 = BatchNorm(planes)\n",
    "        self.conv3 = nn.Conv2d(planes,planes*4, kernel_size=1, bias=False)\n",
    "        self.bn3 = BatchNorm(planes*4)\n",
    "        self.relu = nn.ReLU(inplace= True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual # f(x) + x\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Resnet class. make layers\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, output_stride, BatchNorm, pretrained = True, url = None):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        blocks = [1, 2, 4]\n",
    "        if output_stride == 16:\n",
    "            strides = [1, 2, 2, 1]\n",
    "            dilations = [1, 1, 1, 2]\n",
    "        elif output_stride == 8:\n",
    "            strides = [1, 2, 1, 1]\n",
    "            dilations = [1, 1, 2, 4]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "        # Modules\n",
    "        self.conv1 = nn.Conv2d(3, 64, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = BatchNorm(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride = strides[0],\n",
    "                                        dilation = dilations[0], BatchNorm=BatchNorm,\n",
    "        )\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride = strides[1],\n",
    "                                        dilation= dilations[1], BatchNorm=BatchNorm)\n",
    "        self.layer3 = self._make_layer(block, 128, layers[2], stride = strides[2],\n",
    "                                        dilation= dilations[2], BatchNorm=BatchNorm)\n",
    "        self.layer4 = self._make_layer(block, 128, layers[2], stride = strides[2],\n",
    "                                        dilation= dilations[2], BatchNorm=BatchNorm)\n",
    "\n",
    "        \n",
    "        self._init_weight()\n",
    "        if pretrained:\n",
    "            print(\"load pretrained RESNET model's weight\")\n",
    "            self._load_pretrained_model(url)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, BatchNorm=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            #self.inplanes: input_channel\n",
    "            downsample = nn.Sequential(                \n",
    "                nn.Conv2d(\n",
    "                    self.inplanes, planes*block.expension,\n",
    "                    kernel_size=1, stride=stride,bias=False,),\n",
    "                BatchNorm(planes*block.expansion),\n",
    "            )\n",
    "            \n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride, dilation, downsample, BatchNorm=BatchNorm)\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(self.inplanes, planes, dilation=dilation, BatchNorm=BatchNorm)\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_MG_unit(\n",
    "        self, block, planes, blocks, stride=1, dilation=1, BatchNorm=None\n",
    "    ):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.inplanes, planes*block.expansion, kernel_size=1,\n",
    "                    stride = stride, bias=False,\n",
    "                ),\n",
    "                BatchNorm(planes * block.expansion),\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride,dilation=blocks[0]*dilation,\n",
    "                downsample=downsample,BatchNorm = BatchNorm,\n",
    "            )\n",
    "        )\n",
    "        self.inplanes =planes *block.expansion\n",
    "        for i in range(1, len(blocks)):\n",
    "            layers.append(\n",
    "                block(self.inplanes,planes,stride = 1,\n",
    "                      dilation=blocks[i]*dilation, BatchNorm=BatchNorm,)\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, input, intercept=False):\n",
    "        x = self.conv1(input) # Conv2d(3, 64)\n",
    "        x = self.bn1(x) # Batchnorm(64)\n",
    "        x = self.relu(x) # ReLU\n",
    "        x = self.maxpool(x) # MaxPool2d\n",
    "\n",
    "        x_1 = self.layer1(x)\n",
    "        x_2 = self.layer2(x_1)\n",
    "        x_3 = self.layer3(x_2)\n",
    "        x_4 = self.layer4(x_3)\n",
    "        if intercept is True:\n",
    "            return x_1, x_3, x_4\n",
    "        return x_4, x_1\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n",
    "            elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def ResNet101(output_stride, BatchNorm, pretrained=True):\n",
    "    r'''Construct a ResNet-101 model\n",
    "    Args:\n",
    "        pretrained(bool): If True, returns a model pre-trained on ImageNet\n",
    "    '''\n",
    "    print(\"Using Resnet101 as a Backbone Network\")\n",
    "    model = ResNet(\n",
    "        Bottleneck, [3, 4, 23, 3], output_stride, BatchNorm,\n",
    "        pretrained=pretrained, url=model_urls['resnet101'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\imgseg\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "from models.sync_batchnorm.batchnorm import SynchronizedBatchNorm2d\n",
    "from models.assp import build_aspp\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    def __init__(self, num_classes = 5, out_dim = 256):\n",
    "        super(classifier, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(out_dim, out_dim, kernel_size=1, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_dim, num_classes, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, x, expand = None):\n",
    "        cls = self.classifier(x)\n",
    "        return cls # b x num_class\n",
    "\n",
    "class Projector(nn.Module):\n",
    "    def __init__(self, out_dim = 256):\n",
    "        super(Projector, self).__init__()\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Conv2d()\n",
    "            nn.ReLU()\n",
    "            nn.Conv2d()\n",
    "        )\n",
    "\n",
    "\n",
    "class DeepLab_temp(nn.Module):\n",
    "    def __init__(self, output_stride = 16, resnet_name = 101):\n",
    "        super(DeepLab_temp, self).__init__()\n",
    "        BatchNorm = SynchronizedBatchNorm2d\n",
    "\n",
    "        self.backbone = ResNet101(output_stride, BatchNorm)\n",
    "    \n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, input):\n",
    "        x, low_level_feat = self.backbone(input)\n",
    "        return x, low_level_feat\n",
    "\n",
    "    def get_backbone_params(self):\n",
    "        modules = [self.backbone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = './'\n",
    "# Root directory\n",
    "PROJECT_DIR = os.path.dirname(__file__)\n",
    "\n",
    "# Load config\n",
    "config_path = os.path.join(PROJECT_DIR, 'config', 'train_config.yml')\n",
    "config = load_yaml(config_path)\n",
    "\n",
    "# Train Serial\n",
    "kst = timezone(timedelta(hours=9))\n",
    "train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Recorder directory\n",
    "RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n",
    "os.makedirs(RECORDER_DIR, exist_ok=True)\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data', config['DIRECTORY']['dataset'])\n",
    "\n",
    "# GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config['gpu_id']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "# Setup random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (477171462.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [9]\u001b[1;36m\u001b[0m\n\u001b[1;33m    metrics =\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Setup dataloader\n",
    "batch_size = 5\n",
    "num_classes = 5\n",
    "\n",
    "train_dataset, valid_dataset = get_dataset(config)\n",
    "data_loader = BuildDataLoader(num_labels = 5, dataset_path = \"\", batch_size = 5)\n",
    "\n",
    "\n",
    "train_l_loader, train_u_loader, valid_l_loader, _ = data_loader.build()\n",
    "print(\"Train set: {}, train unsup set: {}, Val set: {}\".format(len(train_l_loader), len(train_u_loader), len(valid_l_loader)))\n",
    "\n",
    "####\n",
    "#set up model (all models are 'constructed at network.modeling)\n",
    "encode = DeepLabv3Plus()\n",
    "decode = Decoder().cuda()\n",
    "elnetwork = ELNetwork(num_classes).cuda()\n",
    "model = DeepLabv3Plus()\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "#set up metrics\n",
    "metrics = \n",
    "    \n",
    "#####\n",
    "#set up optimizer \n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(), lr=config['lr'], weight_decay=config['weight_decay']\n",
    ")\n",
    "if config['lr_policy'] == 'poly':\n",
    "    scheduler = PolyLR\n",
    "elif config['lr_policy'] == 'step':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['step_size'], gamma=0.1)\n",
    "\n",
    "# Gradient scaling 그래디언트가 samll magnitudes에 \n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "######\n",
    "#set up criterion\n",
    "# criterion = utils.get_loss(config['loss_type'])\n",
    "if config['loss_type'] == 'focal_loss':\n",
    "    criterion = utils.FocalLoss(ignore_index = 255, size_average = True)\n",
    "elif config['loss_type'] == 'cross_entropy':\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=255, reduction = 'mean')\n",
    "\n",
    "def save_ckpt(path):\n",
    "    \"\"\"save current model\"\"\"\n",
    "    torch.save()\n",
    "    print(\"Model saved as {}\".format(path))\n",
    "\n",
    "mkdir('checkpoints')\n",
    "\n",
    "# Restore\n",
    "best_score == 0.0\n",
    "cur_itrs = 0\n",
    "cur_epochs = 0\n",
    "if config['ckpt'] not None and os.path.isfile(config['ckpt']): # if checkpoint is available\n",
    "    checkpoint = torch.load(config['ckpt'], map_location = torch.device['cpu'])\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "else:\n",
    "    print(\"[!] Retrain\")\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "# train Loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('imgseg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d845fd51fc75d2ae1670e74f4f446c0d06dfba8d4cc9ca0062c740d6c529ae66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
