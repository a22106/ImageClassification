{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# 픽셀 값을 0~1 사이로 정규화\n",
    "train_images, test_images = train_images / 255.0, test_images/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN은 batch 크기를 제외하고 (이미지 높이, 너비, 컬러 채널) 크기의 텐서를 입력으로 받음\n",
    "MNIST 데이터는 흑백이미지이기떄문에 컬러 채널(channel)이 하나지만 컬러 이미지는 (R, G, B) 세 개의 채널을 가진다.\n",
    "이 예에서 MNIST 이미지 포멧 (28, 28, 1) 크기의 입력을 처리하는 CNN을 정의함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2D와 MaxPooling2D 층의 출력은 (높이, 너비, 채널) 크기의 3D텐서 \n",
    "\n",
    "### 마지막에 Dense 층 추가하기\n",
    "모델을 완성하려면 마지막 합성곱 층의 출력 텐서(크기 (4, 4, 64))를 하나 이상의 Dense 층에 주입하여 분류를 수행함.\n",
    "Dense층은 벡터(1D)를 입력으로 받는데 현재 출력은 3D이므로 flatten메서드로 출력을 1D로 펼침\n",
    "MNIST데이터는 10개의 클래스가 있으므로 마지막 Dense층에 10개의 출력과 softmax 활성화 함수를 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1504 - accuracy: 0.9534\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0464 - accuracy: 0.9855\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0336 - accuracy: 0.9896\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0251 - accuracy: 0.9922\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0208 - accuracy: 0.9935\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0164 - accuracy: 0.9946\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0129 - accuracy: 0.9959\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0118 - accuracy: 0.9962\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0088 - accuracy: 0.9973\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0072 - accuracy: 0.9977\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0066 - accuracy: 0.9978\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0053 - accuracy: 0.9985\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0056 - accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f98492d10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0501 - accuracy: 0.9916 - 870ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991599977016449\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b78a14297dbe569e25ee4da826df63b85b37fbdd479f87706c722d10f0636c27"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
